{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df007d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4e7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:/python/Emotion Detection/Data/train\" \n",
    "test_dir = \"D:/python/Emotion Detection/Data/test\"   \n",
    "img_size = 48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06577847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
    "                                         width_shift_range = 0.1,\n",
    "                                         height_shift_range = 0.1,\n",
    "                                         horizontal_flip = True,\n",
    "                                         rescale = 1./255,\n",
    "                                         #zoom_range = 0.2,\n",
    "                                         validation_split = 0.2\n",
    "                                        )\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb2706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32383 images belonging to 7 classes.\n",
      "Found 1432 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (img_size,img_size),\n",
    "                                                    batch_size = 64,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\"\n",
    "                                                   )\n",
    "validation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              batch_size = 64,\n",
    "                                                              color_mode = \"grayscale\",\n",
    "                                                              class_mode = \"categorical\",\n",
    "                                                              subset = \"validation\"\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tensorflow.keras.models.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb53e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=0.0001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cfe26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 4,496,903\n",
      "Trainable params: 4,492,935\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "batch_size = 64\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fc01a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint(filepath=\"best_model_sequential_new.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "\n",
    "\n",
    "call_back = [mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea49b9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "500/500 [==============================] - 1101s 2s/step - loss: 7.4473 - accuracy: 0.3181 - val_loss: 6.7752 - val_accuracy: 0.3135\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.25559 to 0.31355, saving model to best_model_sequential.h5\n",
      "Epoch 2/60\n",
      "500/500 [==============================] - 1098s 2s/step - loss: 6.0631 - accuracy: 0.3868 - val_loss: 5.5305 - val_accuracy: 0.3743\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.31355 to 0.37430, saving model to best_model_sequential.h5\n",
      "Epoch 3/60\n",
      "500/500 [==============================] - 1178s 2s/step - loss: 4.9149 - accuracy: 0.4373 - val_loss: 4.5301 - val_accuracy: 0.3939\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.37430 to 0.39385, saving model to best_model_sequential.h5\n",
      "Epoch 4/60\n",
      "500/500 [==============================] - 1255s 3s/step - loss: 4.0134 - accuracy: 0.4649 - val_loss: 3.7725 - val_accuracy: 0.4274\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.39385 to 0.42737, saving model to best_model_sequential.h5\n",
      "Epoch 5/60\n",
      "500/500 [==============================] - 1102s 2s/step - loss: 3.3053 - accuracy: 0.4918 - val_loss: 3.1185 - val_accuracy: 0.4427\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.42737 to 0.44274, saving model to best_model_sequential.h5\n",
      "Epoch 6/60\n",
      "500/500 [==============================] - 1098s 2s/step - loss: 2.7938 - accuracy: 0.5125 - val_loss: 2.8517 - val_accuracy: 0.4427\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.44274\n",
      "Epoch 7/60\n",
      "500/500 [==============================] - 1045s 2s/step - loss: 2.4003 - accuracy: 0.5361 - val_loss: 2.3581 - val_accuracy: 0.4693\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.44274 to 0.46927, saving model to best_model_sequential.h5\n",
      "Epoch 8/60\n",
      "500/500 [==============================] - 749s 1s/step - loss: 2.1078 - accuracy: 0.5550 - val_loss: 2.1259 - val_accuracy: 0.5070\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.46927 to 0.50698, saving model to best_model_sequential.h5\n",
      "Epoch 9/60\n",
      "500/500 [==============================] - 751s 2s/step - loss: 1.8953 - accuracy: 0.5711 - val_loss: 1.9384 - val_accuracy: 0.5133\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.50698 to 0.51327, saving model to best_model_sequential.h5\n",
      "Epoch 10/60\n",
      "500/500 [==============================] - 746s 1s/step - loss: 1.7368 - accuracy: 0.5845 - val_loss: 1.7849 - val_accuracy: 0.5412\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.51327 to 0.54120, saving model to best_model_sequential.h5\n",
      "Epoch 11/60\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.6190 - accuracy: 0.5950 - val_loss: 1.6410 - val_accuracy: 0.5608\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.54120 to 0.56075, saving model to best_model_sequential.h5\n",
      "Epoch 12/60\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.5358 - accuracy: 0.6028 - val_loss: 1.5630 - val_accuracy: 0.5649\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.56075 to 0.56494, saving model to best_model_sequential.h5\n",
      "Epoch 13/60\n",
      "500/500 [==============================] - 760s 2s/step - loss: 1.4855 - accuracy: 0.6091 - val_loss: 1.6369 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.56494\n",
      "Epoch 14/60\n",
      "500/500 [==============================] - 743s 1s/step - loss: 1.4427 - accuracy: 0.6164 - val_loss: 1.5138 - val_accuracy: 0.5803\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.56494 to 0.58031, saving model to best_model_sequential.h5\n",
      "Epoch 15/60\n",
      "500/500 [==============================] - 746s 1s/step - loss: 1.4060 - accuracy: 0.6223 - val_loss: 1.4581 - val_accuracy: 0.5908\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.58031 to 0.59078, saving model to best_model_sequential.h5\n",
      "Epoch 16/60\n",
      "500/500 [==============================] - 26538s 53s/step - loss: 1.3800 - accuracy: 0.6240 - val_loss: 1.4805 - val_accuracy: 0.5908\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59078\n",
      "Epoch 17/60\n",
      "500/500 [==============================] - 761s 2s/step - loss: 1.3442 - accuracy: 0.6336 - val_loss: 1.4571 - val_accuracy: 0.5950\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.59078 to 0.59497, saving model to best_model_sequential.h5\n",
      "Epoch 18/60\n",
      "500/500 [==============================] - 753s 2s/step - loss: 1.3305 - accuracy: 0.6400 - val_loss: 1.4394 - val_accuracy: 0.5873\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59497\n",
      "Epoch 19/60\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.3117 - accuracy: 0.6469 - val_loss: 1.4058 - val_accuracy: 0.6061\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.59497 to 0.60615, saving model to best_model_sequential.h5\n",
      "Epoch 20/60\n",
      "500/500 [==============================] - 744s 1s/step - loss: 1.2990 - accuracy: 0.6478 - val_loss: 1.4180 - val_accuracy: 0.5950\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.60615\n",
      "Epoch 21/60\n",
      "500/500 [==============================] - 758s 2s/step - loss: 1.2946 - accuracy: 0.6530 - val_loss: 1.3744 - val_accuracy: 0.6131\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.60615 to 0.61313, saving model to best_model_sequential.h5\n",
      "Epoch 22/60\n",
      "500/500 [==============================] - 824s 2s/step - loss: 1.2797 - accuracy: 0.6568 - val_loss: 1.3705 - val_accuracy: 0.6278\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.61313 to 0.62779, saving model to best_model_sequential.h5\n",
      "Epoch 23/60\n",
      "500/500 [==============================] - 749s 1s/step - loss: 1.2803 - accuracy: 0.6602 - val_loss: 1.3626 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.62779\n",
      "Epoch 24/60\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.2703 - accuracy: 0.6613 - val_loss: 1.3524 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.62779\n",
      "Epoch 25/60\n",
      "500/500 [==============================] - 749s 1s/step - loss: 1.2659 - accuracy: 0.6634 - val_loss: 1.3947 - val_accuracy: 0.6180\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.62779\n",
      "Epoch 26/60\n",
      "500/500 [==============================] - 824s 2s/step - loss: 1.2597 - accuracy: 0.6676 - val_loss: 1.3978 - val_accuracy: 0.6103\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.62779\n",
      "Epoch 27/60\n",
      "500/500 [==============================] - 901s 2s/step - loss: 1.2547 - accuracy: 0.6696 - val_loss: 1.3972 - val_accuracy: 0.6166\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.62779\n",
      "Epoch 28/60\n",
      "500/500 [==============================] - 929s 2s/step - loss: 1.2463 - accuracy: 0.6716 - val_loss: 1.3968 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.62779\n",
      "Epoch 29/60\n",
      "500/500 [==============================] - 915s 2s/step - loss: 1.2452 - accuracy: 0.6752 - val_loss: 1.4466 - val_accuracy: 0.6027\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.62779\n",
      "Epoch 30/60\n",
      "500/500 [==============================] - 932s 2s/step - loss: 1.2433 - accuracy: 0.6744 - val_loss: 1.3729 - val_accuracy: 0.6334\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.62779 to 0.63338, saving model to best_model_sequential.h5\n",
      "Epoch 31/60\n",
      "500/500 [==============================] - 843s 2s/step - loss: 1.2413 - accuracy: 0.6756 - val_loss: 1.3221 - val_accuracy: 0.6369\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.63338 to 0.63687, saving model to best_model_sequential.h5\n",
      "Epoch 32/60\n",
      "500/500 [==============================] - 759s 2s/step - loss: 1.2287 - accuracy: 0.6809 - val_loss: 1.3391 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.63687 to 0.63827, saving model to best_model_sequential.h5\n",
      "Epoch 33/60\n",
      "500/500 [==============================] - 761s 2s/step - loss: 1.2260 - accuracy: 0.6798 - val_loss: 1.3391 - val_accuracy: 0.6466\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.63827 to 0.64665, saving model to best_model_sequential.h5\n",
      "Epoch 34/60\n",
      "500/500 [==============================] - 751s 2s/step - loss: 1.2285 - accuracy: 0.6819 - val_loss: 1.3025 - val_accuracy: 0.6411\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64665\n",
      "Epoch 35/60\n",
      "500/500 [==============================] - 750s 1s/step - loss: 1.2198 - accuracy: 0.6865 - val_loss: 1.2843 - val_accuracy: 0.6613\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.64665 to 0.66131, saving model to best_model_sequential.h5\n",
      "Epoch 36/60\n",
      "500/500 [==============================] - 754s 2s/step - loss: 1.2156 - accuracy: 0.6900 - val_loss: 1.3912 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66131\n",
      "Epoch 37/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 747s 1s/step - loss: 1.2161 - accuracy: 0.6882 - val_loss: 1.2960 - val_accuracy: 0.6487\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66131\n",
      "Epoch 38/60\n",
      "500/500 [==============================] - 747s 1s/step - loss: 1.2067 - accuracy: 0.6880 - val_loss: 1.3489 - val_accuracy: 0.6320\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66131\n",
      "Epoch 39/60\n",
      "500/500 [==============================] - 751s 2s/step - loss: 1.2081 - accuracy: 0.6894 - val_loss: 1.3321 - val_accuracy: 0.6411\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66131\n",
      "Epoch 40/60\n",
      "500/500 [==============================] - 752s 2s/step - loss: 1.2009 - accuracy: 0.6927 - val_loss: 1.3079 - val_accuracy: 0.6557\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66131\n",
      "Epoch 41/60\n",
      "500/500 [==============================] - 756s 2s/step - loss: 1.1970 - accuracy: 0.6941 - val_loss: 1.3075 - val_accuracy: 0.6453\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66131\n",
      "Epoch 42/60\n",
      "500/500 [==============================] - 869s 2s/step - loss: 1.1875 - accuracy: 0.6983 - val_loss: 1.3453 - val_accuracy: 0.6404\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66131\n",
      "Epoch 43/60\n",
      "500/500 [==============================] - 869s 2s/step - loss: 1.1953 - accuracy: 0.6950 - val_loss: 1.3005 - val_accuracy: 0.6432\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66131\n",
      "Epoch 44/60\n",
      "500/500 [==============================] - 4875s 10s/step - loss: 1.1978 - accuracy: 0.6974 - val_loss: 1.3585 - val_accuracy: 0.6362\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66131\n",
      "Epoch 45/60\n",
      "500/500 [==============================] - 782s 2s/step - loss: 1.1840 - accuracy: 0.6981 - val_loss: 1.3258 - val_accuracy: 0.6536\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66131\n",
      "Epoch 46/60\n",
      "500/500 [==============================] - 793s 2s/step - loss: 1.1880 - accuracy: 0.6999 - val_loss: 1.3767 - val_accuracy: 0.6243\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66131\n",
      "Epoch 47/60\n",
      "500/500 [==============================] - 802s 2s/step - loss: 1.1913 - accuracy: 0.7002 - val_loss: 1.3779 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66131\n",
      "Epoch 48/60\n",
      "500/500 [==============================] - 895s 2s/step - loss: 1.1863 - accuracy: 0.6997 - val_loss: 1.3203 - val_accuracy: 0.6529\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66131\n",
      "Epoch 49/60\n",
      "500/500 [==============================] - 927s 2s/step - loss: 1.1795 - accuracy: 0.7037 - val_loss: 1.2832 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.66131 to 0.66411, saving model to best_model_sequential.h5\n",
      "Epoch 50/60\n",
      "500/500 [==============================] - 988s 2s/step - loss: 1.1746 - accuracy: 0.7016 - val_loss: 1.2875 - val_accuracy: 0.6599\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66411\n",
      "Epoch 51/60\n",
      "500/500 [==============================] - 1008s 2s/step - loss: 1.1758 - accuracy: 0.7046 - val_loss: 1.2953 - val_accuracy: 0.6676\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.66411 to 0.66760, saving model to best_model_sequential.h5\n",
      "Epoch 52/60\n",
      "500/500 [==============================] - 1044s 2s/step - loss: 1.1782 - accuracy: 0.7036 - val_loss: 1.3117 - val_accuracy: 0.6480\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.66760\n",
      "Epoch 53/60\n",
      "500/500 [==============================] - 993s 2s/step - loss: 1.1788 - accuracy: 0.7068 - val_loss: 1.3247 - val_accuracy: 0.6529\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.66760\n",
      "Epoch 54/60\n",
      "500/500 [==============================] - 974s 2s/step - loss: 1.1711 - accuracy: 0.7087 - val_loss: 1.9035 - val_accuracy: 0.5615\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.66760\n",
      "Epoch 55/60\n",
      "500/500 [==============================] - 986s 2s/step - loss: 1.1729 - accuracy: 0.7074 - val_loss: 1.3149 - val_accuracy: 0.6466\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.66760\n",
      "Epoch 56/60\n",
      "500/500 [==============================] - 999s 2s/step - loss: 1.1709 - accuracy: 0.7100 - val_loss: 1.3548 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.66760\n",
      "Epoch 57/60\n",
      "500/500 [==============================] - 1039s 2s/step - loss: 1.1646 - accuracy: 0.7117 - val_loss: 1.3022 - val_accuracy: 0.6522\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.66760\n",
      "Epoch 58/60\n",
      "500/500 [==============================] - 978s 2s/step - loss: 1.1570 - accuracy: 0.7124 - val_loss: 1.3858 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.66760\n",
      "Epoch 59/60\n",
      " 84/500 [====>.........................] - ETA: 13:38 - loss: 1.1281 - accuracy: 0.7228"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = train_generator,epochs = epochs,steps_per_epoch=500,validation_data = validation_generator,callbacks=[mc]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "184eed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('best_model_sequential_weights.h5')\n",
    "# model.save('best_model_sequential_save.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d3355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_model = load_model('best_model_sequential.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86a070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = dict(zip( train_generator.class_indices.values(), train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4a09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The emotion of the person in the image is sad\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"D:/python/Emotion Detection/0003.jpg\"\n",
    "img = load_img(path, target_size=(48,48),color_mode = \"grayscale\" )\n",
    "\n",
    "i = img_to_array(img)/255\n",
    "input_arr = np.array([i])\n",
    "input_arr.shape\n",
    "\n",
    "pred = np.argmax(em_model.predict(input_arr))\n",
    "\n",
    "print(f\" The emotion of the person in the image is {op[pred]}\")\n",
    " \n",
    "plt.imshow(input_arr[0])\n",
    "plt.title(\"input image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
